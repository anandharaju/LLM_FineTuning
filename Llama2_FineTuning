{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Llama Fine Tuning**\n\nReading Source: https://www.datacamp.com/tutorial/fine-tuning-llama-2","metadata":{}},{"cell_type":"code","source":"%%capture\n%pip install accelerate peft bitsandbytes transformers trl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T21:27:38.502263Z","iopub.execute_input":"2024-11-06T21:27:38.502865Z","iopub.status.idle":"2024-11-06T21:28:07.869675Z","shell.execute_reply.started":"2024-11-06T21:27:38.502806Z","shell.execute_reply":"2024-11-06T21:28:07.868649Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nimport torch\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    TrainingArguments,\n    pipeline,\n    logging,\n)\nfrom peft import LoraConfig\nfrom trl import SFTTrainer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T21:28:24.948366Z","iopub.execute_input":"2024-11-06T21:28:24.949302Z","iopub.status.idle":"2024-11-06T21:28:45.070752Z","shell.execute_reply.started":"2024-11-06T21:28:24.949256Z","shell.execute_reply":"2024-11-06T21:28:45.070029Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Model from Hugging Face hub\nbase_model = \"NousResearch/Llama-2-7b-chat-hf\"\n\n# New instruction dataset\nguanaco_dataset = \"mlabonne/guanaco-llama2-1k\"\n\n# Fine-tuned model\nnew_model = \"llama-2-7b-chat-guanaco\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T21:28:47.070535Z","iopub.execute_input":"2024-11-06T21:28:47.071723Z","iopub.status.idle":"2024-11-06T21:28:47.076152Z","shell.execute_reply.started":"2024-11-06T21:28:47.071666Z","shell.execute_reply":"2024-11-06T21:28:47.075271Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## Loading dataset, model, and tokenizer","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset(guanaco_dataset, split=\"train\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T21:28:59.378918Z","iopub.execute_input":"2024-11-06T21:28:59.379312Z","iopub.status.idle":"2024-11-06T21:29:01.593986Z","shell.execute_reply.started":"2024-11-06T21:28:59.379260Z","shell.execute_reply":"2024-11-06T21:29:01.593232Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/1.02k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9da0d56c3531468ab2e6c51421a67cc7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(â€¦)-00000-of-00001-9ad84bb9cf65a42f.parquet:   0%|          | 0.00/967k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76ce830a35de41d29551059ccaf72133"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d42e161fa5a74565966dd3b16d257987"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/mlabonne--guanaco-llama2-1k-f1f1134768f90029/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901. Subsequent calls will reuse this data.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T21:29:03.550568Z","iopub.execute_input":"2024-11-06T21:29:03.550958Z","iopub.status.idle":"2024-11-06T21:29:03.555435Z","shell.execute_reply.started":"2024-11-06T21:29:03.550921Z","shell.execute_reply":"2024-11-06T21:29:03.554387Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## 4-bit quantization configuration","metadata":{}},{"cell_type":"code","source":"compute_dtype = getattr(torch, \"float16\")\n\nquant_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=compute_dtype,\n    bnb_4bit_use_double_quant=False,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T21:29:05.565631Z","iopub.execute_input":"2024-11-06T21:29:05.566018Z","iopub.status.idle":"2024-11-06T21:29:05.572051Z","shell.execute_reply.started":"2024-11-06T21:29:05.565982Z","shell.execute_reply":"2024-11-06T21:29:05.571084Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Loading Llama 2 model","metadata":{}},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    quantization_config=quant_config,\n    device_map={\"\": 0}\n)\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T21:29:07.791172Z","iopub.execute_input":"2024-11-06T21:29:07.791879Z","iopub.status.idle":"2024-11-06T21:30:22.684666Z","shell.execute_reply.started":"2024-11-06T21:29:07.791830Z","shell.execute_reply":"2024-11-06T21:30:22.683883Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/583 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48f1709068394072b9ab1ccae69cda1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ff4f074e54d46549bc30dd97bbf4e8b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2a7a3b90d06444696793dd7cff83a4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e19c0472ab814a3c91bee833954f79f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6461e7515134401eae84e13fc76b7205"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24c4d0dc733948d4adfd985bc7d89718"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f170253d891245fc8649e9bc18912875"}},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"## Loading tokenizer","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T21:30:24.399896Z","iopub.execute_input":"2024-11-06T21:30:24.400304Z","iopub.status.idle":"2024-11-06T21:30:25.751572Z","shell.execute_reply.started":"2024-11-06T21:30:24.400263Z","shell.execute_reply":"2024-11-06T21:30:25.750292Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/746 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7df32af158c9421ca5e472ac9d306b00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d18c0600c4614450ba07a43270285953"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38640d5e150b4afbacc775826505bb9f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/21.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d09e5179f66c4c75b88ab119a2e7c9e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/435 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a2664213c2e47b081b62cd78d379880"}},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"## PEFT (Parameter efficient fine tuning) parameters","metadata":{}},{"cell_type":"code","source":"peft_params = LoraConfig(\n    lora_alpha=16,\n    lora_dropout=0.1,\n    r=64,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T21:30:29.504313Z","iopub.execute_input":"2024-11-06T21:30:29.504683Z","iopub.status.idle":"2024-11-06T21:30:29.509159Z","shell.execute_reply.started":"2024-11-06T21:30:29.504648Z","shell.execute_reply":"2024-11-06T21:30:29.508272Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## Training parameters\n\nHyperparameters List:\n\noutput_dir: The output directory is where the model predictions and checkpoints will be stored.\n\nnum_train_epochs: One training epoch.\n\nfp16/bf16: Disable fp16/bf16 training.\n\nper_device_train_batch_size: Batch size per GPU for training.\n\nper_device_eval_batch_size: Batch size per GPU for evaluation.\n\ngradient_accumulation_steps: This refers to the number of steps required to accumulate the gradients during the update process.\n\ngradient_checkpointing: Enabling gradient checkpointing.\n\nmax_grad_norm: Gradient clipping.\n\nlearning_rate: Initial learning rate.\n\nweight_decay: Weight decay is applied to all layers except bias/LayerNorm weights.\n\nOptim: Model optimizer (AdamW optimizer).\n\nlr_scheduler_type: Learning rate schedule.\n\nmax_steps: Number of training steps.\n\nwarmup_ratio: Ratio of steps for a linear warmup.\n\ngroup_by_length: This can significantly improve performance and accelerate the training process.\n\nsave_steps: Save checkpoint every 25 update steps.\n\nlogging_steps: Log every 25 update steps.","metadata":{}},{"cell_type":"code","source":"training_params = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=1,\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=1,\n    optim=\"paged_adamw_32bit\",\n    save_steps=25,\n    logging_steps=25,\n    learning_rate=2e-4,\n    weight_decay=0.001,\n    fp16=False,\n    bf16=False,\n    max_grad_norm=0.3,\n    max_steps=-1,\n    warmup_ratio=0.03,\n    group_by_length=True,\n    lr_scheduler_type=\"constant\",\n    report_to=\"tensorboard\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T21:31:26.192401Z","iopub.execute_input":"2024-11-06T21:31:26.193084Z","iopub.status.idle":"2024-11-06T21:31:26.220749Z","shell.execute_reply.started":"2024-11-06T21:31:26.193043Z","shell.execute_reply":"2024-11-06T21:31:26.219995Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset,\n    peft_config=peft_params,\n    dataset_text_field=\"text\",\n    max_seq_length=None,\n    tokenizer=tokenizer,\n    args=training_params,\n    packing=False,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T21:31:27.388298Z","iopub.execute_input":"2024-11-06T21:31:27.389027Z","iopub.status.idle":"2024-11-06T21:31:28.444253Z","shell.execute_reply.started":"2024-11-06T21:31:27.388985Z","shell.execute_reply":"2024-11-06T21:31:28.443520Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:309: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62f0e2a5b12547288b20da726e19aacb"}},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T21:31:51.461592Z","iopub.execute_input":"2024-11-06T21:31:51.462462Z","iopub.status.idle":"2024-11-06T22:12:12.375935Z","shell.execute_reply.started":"2024-11-06T21:31:51.462421Z","shell.execute_reply":"2024-11-06T22:12:12.374860Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1000/1000 40:14, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>25</td>\n      <td>1.425200</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.594100</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>1.251700</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.512800</td>\n    </tr>\n    <tr>\n      <td>125</td>\n      <td>1.227500</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>1.475900</td>\n    </tr>\n    <tr>\n      <td>175</td>\n      <td>1.073000</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.494200</td>\n    </tr>\n    <tr>\n      <td>225</td>\n      <td>1.182100</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>1.553700</td>\n    </tr>\n    <tr>\n      <td>275</td>\n      <td>1.166300</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>1.425900</td>\n    </tr>\n    <tr>\n      <td>325</td>\n      <td>1.209500</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>1.414600</td>\n    </tr>\n    <tr>\n      <td>375</td>\n      <td>1.084900</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>1.464700</td>\n    </tr>\n    <tr>\n      <td>425</td>\n      <td>1.065900</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>1.330700</td>\n    </tr>\n    <tr>\n      <td>475</td>\n      <td>1.265400</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>1.365600</td>\n    </tr>\n    <tr>\n      <td>525</td>\n      <td>1.154100</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>1.469800</td>\n    </tr>\n    <tr>\n      <td>575</td>\n      <td>1.167000</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>1.234700</td>\n    </tr>\n    <tr>\n      <td>625</td>\n      <td>1.101100</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>1.721800</td>\n    </tr>\n    <tr>\n      <td>675</td>\n      <td>1.105400</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>1.512300</td>\n    </tr>\n    <tr>\n      <td>725</td>\n      <td>1.091800</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>1.468600</td>\n    </tr>\n    <tr>\n      <td>775</td>\n      <td>1.259300</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>1.305600</td>\n    </tr>\n    <tr>\n      <td>825</td>\n      <td>1.251000</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>1.398400</td>\n    </tr>\n    <tr>\n      <td>875</td>\n      <td>1.156600</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>1.374300</td>\n    </tr>\n    <tr>\n      <td>925</td>\n      <td>1.106400</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>1.420300</td>\n    </tr>\n    <tr>\n      <td>975</td>\n      <td>1.083200</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>1.376900</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1000, training_loss=1.308550672531128, metrics={'train_runtime': 2419.589, 'train_samples_per_second': 0.413, 'train_steps_per_second': 0.413, 'total_flos': 1.679542884421632e+16, 'train_loss': 1.308550672531128, 'epoch': 1.0})"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"trainer.model.save_pretrained(new_model)\ntrainer.tokenizer.save_pretrained(new_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T22:32:47.932744Z","iopub.execute_input":"2024-11-06T22:32:47.933220Z","iopub.status.idle":"2024-11-06T22:32:48.510636Z","shell.execute_reply.started":"2024-11-06T22:32:47.933178Z","shell.execute_reply":"2024-11-06T22:32:48.509752Z"}},"outputs":[{"name":"stderr","text":"Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"('llama-2-7b-chat-guanaco/tokenizer_config.json',\n 'llama-2-7b-chat-guanaco/special_tokens_map.json',\n 'llama-2-7b-chat-guanaco/tokenizer.model',\n 'llama-2-7b-chat-guanaco/added_tokens.json',\n 'llama-2-7b-chat-guanaco/tokenizer.json')"},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"code","source":"from tensorboard import notebook\nlog_dir = \"results/runs\"\nnotebook.start(\"--logdir {} --port 4000\".format(log_dir))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T22:35:17.450065Z","iopub.execute_input":"2024-11-06T22:35:17.450958Z","iopub.status.idle":"2024-11-06T22:35:17.461286Z","shell.execute_reply.started":"2024-11-06T22:35:17.450914Z","shell.execute_reply":"2024-11-06T22:35:17.460404Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Reusing TensorBoard on port 4000 (pid 162), started 0:00:40 ago. (Use '!kill 162' to kill it.)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n      <iframe id=\"tensorboard-frame-3eb13b9046685257\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-3eb13b9046685257\");\n          const url = new URL(\"/\", window.location);\n          const port = 4000;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"logging.set_verbosity(logging.CRITICAL)\n\nprompt = \"Who is Leonardo Da Vinci?\"\npipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\nresult = pipe(f\"<s>[INST] {prompt} [/INST]\")\nprint(result[0]['generated_text'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T22:36:30.450007Z","iopub.execute_input":"2024-11-06T22:36:30.450650Z","iopub.status.idle":"2024-11-06T22:36:44.283877Z","shell.execute_reply.started":"2024-11-06T22:36:30.450609Z","shell.execute_reply":"2024-11-06T22:36:44.282911Z"}},"outputs":[{"name":"stdout","text":"<s>[INST] Who is Leonardo Da Vinci? [/INST] Leonardo da Vinci (1452-1519) was a renowned Italian polymath, artist, inventor, engineer, and scientist. He is widely regarded as one of the most influential figures of the Renaissance and is known for his contributions to various fields, including painting, sculpture, anatomy, mathematics, engineering, and architecture.\n\nDa Vinci was born in Vinci, Italy, and was trained in art by his father, a local artist. He later moved to Florence, where he became a member of the Medici court and became known for his work as a painter, sculptor, and engineer. His most famous works include the Mona Lisa and The Last Supper.\n\nDa Vinci was also a prolific inventor and engineer, and his designs for machines and machines have been studied and used to this day. He\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"prompt = \"What is Datacamp Career track?\"\nresult = pipe(f\"<s>[INST] {prompt} [/INST]\")\nprint(result[0]['generated_text'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T22:38:06.529990Z","iopub.execute_input":"2024-11-06T22:38:06.530745Z","iopub.status.idle":"2024-11-06T22:38:20.438903Z","shell.execute_reply.started":"2024-11-06T22:38:06.530706Z","shell.execute_reply":"2024-11-06T22:38:20.437792Z"}},"outputs":[{"name":"stdout","text":"<s>[INST] What is Datacamp Career track? [/INST] DataCamp Career Track is a program designed to help individuals gain the skills and knowledge necessary to succeed in a career in data science. The program includes a range of courses and resources, including interactive coding exercises, video lectures, and hands-on projects. Additionally, participants have access to a community of learners and mentors, as well as a range of career support services. The program is designed to be flexible and adaptable to the needs of each individual, allowing learners to set their own pace and focus on the areas of data science that are most relevant to their career goals.\n\nThe DataCamp Career Track is designed to help individuals gain the skills and knowledge necessary to succeed in a career in data science, including data analysis, data visualization, machine learning, and data engineering. The program is open to individuals of all skill levels and backgrounds, and learners can choose to\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":33551,"sourceType":"modelInstanceVersion","modelInstanceId":28083,"modelId":39106}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Llama 3 Fine Tuning","metadata":{}},{"cell_type":"code","source":"%%capture\n%pip install -U transformers \n%pip install -U datasets \n%pip install -U accelerate \n%pip install -U peft \n%pip install -U trl \n%pip install -U bitsandbytes \n%pip install -U wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T18:11:25.054728Z","iopub.execute_input":"2025-03-24T18:11:25.055114Z","iopub.status.idle":"2025-03-24T18:12:18.450619Z","shell.execute_reply.started":"2025-03-24T18:11:25.055086Z","shell.execute_reply":"2025-03-24T18:12:18.449710Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    TrainingArguments,\n    pipeline,\n    logging,\n)\nfrom peft import (\n    LoraConfig,\n    PeftModel,\n    prepare_model_for_kbit_training,\n    get_peft_model,\n)\nimport os, torch, wandb\nfrom datasets import load_dataset\nfrom trl import SFTTrainer, setup_chat_format","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T18:12:18.451750Z","iopub.execute_input":"2025-03-24T18:12:18.452004Z","iopub.status.idle":"2025-03-24T18:12:41.290333Z","shell.execute_reply.started":"2025-03-24T18:12:18.451982Z","shell.execute_reply":"2025-03-24T18:12:41.289664Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\nhf_token = user_secrets.get_secret(\"hf\")\n\nlogin(token = hf_token)\n\nwb_token = user_secrets.get_secret(\"wb\")\n\nwandb.login(key=wb_token)\nrun = wandb.init(\n    project='Fine-tune Llama 3 8B on Medical Dataset', \n    job_type=\"training\", \n    anonymous=\"allow\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T18:12:41.291999Z","iopub.execute_input":"2025-03-24T18:12:41.292755Z","iopub.status.idle":"2025-03-24T18:12:54.563264Z","shell.execute_reply.started":"2025-03-24T18:12:41.292730Z","shell.execute_reply":"2025-03-24T18:12:54.562625Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manandharajuds\u001b[0m (\u001b[33manandharajuds-simon-fraser-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.8"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250324_181248-icm5bfo1</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/anandharajuds-simon-fraser-university/Fine-tune%20Llama%203%208B%20on%20Medical%20Dataset/runs/icm5bfo1?apiKey=3b83f429d264e08e515d9f0b3ce148c93f16629b' target=\"_blank\">zany-plant-2</a></strong> to <a href='https://wandb.ai/anandharajuds-simon-fraser-university/Fine-tune%20Llama%203%208B%20on%20Medical%20Dataset?apiKey=3b83f429d264e08e515d9f0b3ce148c93f16629b' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/anandharajuds-simon-fraser-university/Fine-tune%20Llama%203%208B%20on%20Medical%20Dataset?apiKey=3b83f429d264e08e515d9f0b3ce148c93f16629b' target=\"_blank\">https://wandb.ai/anandharajuds-simon-fraser-university/Fine-tune%20Llama%203%208B%20on%20Medical%20Dataset?apiKey=3b83f429d264e08e515d9f0b3ce148c93f16629b</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/anandharajuds-simon-fraser-university/Fine-tune%20Llama%203%208B%20on%20Medical%20Dataset/runs/icm5bfo1?apiKey=3b83f429d264e08e515d9f0b3ce148c93f16629b' target=\"_blank\">https://wandb.ai/anandharajuds-simon-fraser-university/Fine-tune%20Llama%203%208B%20on%20Medical%20Dataset/runs/icm5bfo1?apiKey=3b83f429d264e08e515d9f0b3ce148c93f16629b</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Do NOT share these links with anyone. They can be used to claim your runs."},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"base_model = \"/kaggle/input/llama-3/transformers/8b-chat-hf/1\"\ndataset_name = \"ruslanmv/ai-medical-chatbot\"\nnew_model = \"llama-3-8b-chat-doctor\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T18:12:54.564468Z","iopub.execute_input":"2025-03-24T18:12:54.564708Z","iopub.status.idle":"2025-03-24T18:12:54.568461Z","shell.execute_reply.started":"2025-03-24T18:12:54.564687Z","shell.execute_reply":"2025-03-24T18:12:54.567868Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"torch_dtype = torch.float16\nattn_implementation = \"eager\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T18:12:54.569481Z","iopub.execute_input":"2025-03-24T18:12:54.569764Z","iopub.status.idle":"2025-03-24T18:12:54.585329Z","shell.execute_reply.started":"2025-03-24T18:12:54.569742Z","shell.execute_reply":"2025-03-24T18:12:54.584604Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# QLoRA config\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch_dtype,\n    bnb_4bit_use_double_quant=True,\n)\n\n# Load model\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    attn_implementation=attn_implementation\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T18:12:54.586154Z","iopub.execute_input":"2025-03-24T18:12:54.586428Z","iopub.status.idle":"2025-03-24T18:14:11.567367Z","shell.execute_reply.started":"2025-03-24T18:12:54.586397Z","shell.execute_reply":"2025-03-24T18:14:11.566717Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51b0ecc890944805b7d7912809ef1264"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(base_model)\nmodel, tokenizer = setup_chat_format(model, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T18:14:11.568186Z","iopub.execute_input":"2025-03-24T18:14:11.568490Z","iopub.status.idle":"2025-03-24T18:14:12.266587Z","shell.execute_reply.started":"2025-03-24T18:14:11.568456Z","shell.execute_reply":"2025-03-24T18:14:12.264714Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-dd49cade07a7>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup_chat_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/trl/models/utils.py\u001b[0m in \u001b[0;36msetup_chat_format\u001b[0;34m(model, tokenizer, format, resize_to_multiple_of)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;31m# check if model already had a chat template\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_template\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0;34m\"Chat template is already added to the tokenizer. If you want to overwrite it, please set it to None\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         )\n","\u001b[0;31mValueError\u001b[0m: Chat template is already added to the tokenizer. If you want to overwrite it, please set it to None"],"ename":"ValueError","evalue":"Chat template is already added to the tokenizer. If you want to overwrite it, please set it to None","output_type":"error"}],"execution_count":7},{"cell_type":"code","source":"# LoRA config\npeft_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']\n)\nmodel = get_peft_model(model, peft_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T18:14:51.484878Z","iopub.execute_input":"2025-03-24T18:14:51.485204Z","iopub.status.idle":"2025-03-24T18:14:52.191746Z","shell.execute_reply.started":"2025-03-24T18:14:51.485177Z","shell.execute_reply":"2025-03-24T18:14:52.191039Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"#Importing the dataset\ndataset = load_dataset(dataset_name, split=\"all\")\ndataset = dataset.shuffle(seed=65).select(range(1000)) # Only use 1000 samples for quick demo\n\ndef format_chat_template(row):\n    row_json = [{\"role\": \"user\", \"content\": row[\"Patient\"][:256]},\n               {\"role\": \"assistant\", \"content\": row[\"Doctor\"][:256]}]\n    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n    return row\n\ndataset = dataset.map(\n    format_chat_template,\n    num_proc=4,\n)\n\ndataset['text'][3]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T18:14:52.321333Z","iopub.execute_input":"2025-03-24T18:14:52.321688Z","iopub.status.idle":"2025-03-24T18:14:57.184909Z","shell.execute_reply.started":"2025-03-24T18:14:52.321658Z","shell.execute_reply":"2025-03-24T18:14:57.184080Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/863 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74c45cf9cb9747578f5c4d26df6bee23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dialogues.parquet:   0%|          | 0.00/142M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"412c812187fb46ae96f24860d40c7b7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/256916 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b86ef57eb8714fb688c33490fcc80ab8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c2c414d94a844fd9b29b57242ea1f38"}},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nFell on sidewalk face first about 8 hrs ago. Swollen, cut lip bruised and cut knee, and hurt pride initially. Now have muscle and shoulder pain, stiff jaw(think this is from the really swollen lip),pain in wrist, and headache. I assume this is all normal b<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nHello and welcome to HCM,The injuries caused on various body parts have to be managed.The cut and swollen lip has to be managed by sterile dressing.The body pains, pain on injured site and jaw pain should be managed by pain killer and muscle relaxant.I sug<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"dataset = dataset.train_test_split(test_size=0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T18:14:57.415888Z","iopub.execute_input":"2025-03-24T18:14:57.416197Z","iopub.status.idle":"2025-03-24T18:14:57.431721Z","shell.execute_reply.started":"2025-03-24T18:14:57.416173Z","shell.execute_reply":"2025-03-24T18:14:57.430864Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"dataset['train']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T18:14:57.859628Z","iopub.execute_input":"2025-03-24T18:14:57.859963Z","iopub.status.idle":"2025-03-24T18:14:57.866394Z","shell.execute_reply.started":"2025-03-24T18:14:57.859937Z","shell.execute_reply":"2025-03-24T18:14:57.865501Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['Description', 'Patient', 'Doctor', 'text'],\n    num_rows: 900\n})"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"training_arguments = TrainingArguments(\n    output_dir=new_model,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    gradient_accumulation_steps=2,\n    optim=\"paged_adamw_32bit\",\n    num_train_epochs=1,\n    evaluation_strategy=\"steps\",\n    eval_steps=0.2,\n    logging_steps=1,\n    warmup_steps=10,\n    logging_strategy=\"steps\",\n    learning_rate=2e-4,\n    fp16=False,\n    bf16=False,\n    group_by_length=True,\n    report_to=\"wandb\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T18:15:03.050093Z","iopub.execute_input":"2025-03-24T18:15:03.050391Z","iopub.status.idle":"2025-03-24T18:15:03.085043Z","shell.execute_reply.started":"2025-03-24T18:15:03.050368Z","shell.execute_reply":"2025-03-24T18:15:03.084102Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"#training_args = SFTConfig()\n\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"test\"],\n    peft_config=peft_config,\n    #max_seq_length=512,\n    #dataset_text_field=\"text\",\n    #tokenizer=tokenizer,\n    args=training_arguments,\n    #packing= False,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T18:15:08.127496Z","iopub.execute_input":"2025-03-24T18:15:08.127848Z","iopub.status.idle":"2025-03-24T18:15:10.331423Z","shell.execute_reply.started":"2025-03-24T18:15:08.127822Z","shell.execute_reply":"2025-03-24T18:15:10.330795Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Converting train dataset to ChatML:   0%|          | 0/900 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16a2afb5e52e4e809da1131a2dbd0407"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Applying chat template to train dataset:   0%|          | 0/900 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4447b5349fa4e1d8775baaa89b34249"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset:   0%|          | 0/900 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df6c74f7075e42b5abd5698b0a3f7cb1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Truncating train dataset:   0%|          | 0/900 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdd717767898409180bc11870f8fd2fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Converting eval dataset to ChatML:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55dc1662c5ea4460991c4b4eca8c46b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Applying chat template to eval dataset:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2993215c69e64d89b5d848adf51f6e23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing eval dataset:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bfea96c8d8740e7bc81a592d5ba4eee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Truncating eval dataset:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e291fa6aa53640aaad94cf72db031c18"}},"metadata":{}},{"name":"stderr","text":"No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T18:15:14.265771Z","iopub.execute_input":"2025-03-24T18:15:14.266102Z","iopub.status.idle":"2025-03-24T18:35:41.951635Z","shell.execute_reply.started":"2025-03-24T18:15:14.266075Z","shell.execute_reply":"2025-03-24T18:35:41.950896Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='450' max='450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [450/450 20:23, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>90</td>\n      <td>2.612200</td>\n      <td>2.553237</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>1.779000</td>\n      <td>2.463870</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>2.750200</td>\n      <td>2.448128</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>2.220500</td>\n      <td>2.415220</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>1.171700</td>\n      <td>2.405278</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=450, training_loss=2.5098389818933273, metrics={'train_runtime': 1227.0033, 'train_samples_per_second': 0.733, 'train_steps_per_second': 0.367, 'total_flos': 5288256236888064.0, 'train_loss': 2.5098389818933273})"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"wandb.finish()\nmodel.config.use_cache = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T18:35:41.952805Z","iopub.execute_input":"2025-03-24T18:35:41.953099Z","iopub.status.idle":"2025-03-24T18:35:42.657470Z","shell.execute_reply.started":"2025-03-24T18:35:41.953074Z","shell.execute_reply":"2025-03-24T18:35:42.656835Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▄▃▁▁</td></tr><tr><td>eval/mean_token_accuracy</td><td>▁▄▄██</td></tr><tr><td>eval/num_tokens</td><td>▁▃▅▆█</td></tr><tr><td>eval/runtime</td><td>▁█▅▆▅</td></tr><tr><td>eval/samples_per_second</td><td>█▁▁▁▁</td></tr><tr><td>eval/steps_per_second</td><td>█▁▁▁▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▂▂▂▃▃▃▃▃▃▃▃▃▃▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇██</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>train/grad_norm</td><td>▄▃▃▄▄▃▂▃▄▃▃▂▃▂▃▂▂▂▃█▂▂▁▂▁▄▂▁▁▂▂▂▂▂▃▂▃▁▂▂</td></tr><tr><td>train/learning_rate</td><td>██████▇▇▇▇▇▇▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▂▂▂▁▁</td></tr><tr><td>train/loss</td><td>█▄▃▆▄▂▄▄▄▃▄▄▃▅▄▄▅▅▂▄▄▆▃▃▄▄▃▂▄▄▃▁▃▃▄▃▃▃▄▃</td></tr><tr><td>train/mean_token_accuracy</td><td>▁▂▃▁▂▂▂▅▃▄▁▄▄▁▂▃▂▁▁▂▃▃▂▂▂▃▂▂▄▂▄▃▂▁▃▃▄▂▂█</td></tr><tr><td>train/num_tokens</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>2.40528</td></tr><tr><td>eval/mean_token_accuracy</td><td>0.48711</td></tr><tr><td>eval/num_tokens</td><td>116787</td></tr><tr><td>eval/runtime</td><td>52.8533</td></tr><tr><td>eval/samples_per_second</td><td>1.892</td></tr><tr><td>eval/steps_per_second</td><td>1.892</td></tr><tr><td>total_flos</td><td>5288256236888064.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>450</td></tr><tr><td>train/grad_norm</td><td>2.24284</td></tr><tr><td>train/learning_rate</td><td>0</td></tr><tr><td>train/loss</td><td>1.1717</td></tr><tr><td>train/mean_token_accuracy</td><td>0.68031</td></tr><tr><td>train/num_tokens</td><td>116787</td></tr><tr><td>train_loss</td><td>2.50984</td></tr><tr><td>train_runtime</td><td>1227.0033</td></tr><tr><td>train_samples_per_second</td><td>0.733</td></tr><tr><td>train_steps_per_second</td><td>0.367</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">zany-plant-2</strong> at: <a href='https://wandb.ai/anandharajuds-simon-fraser-university/Fine-tune%20Llama%203%208B%20on%20Medical%20Dataset/runs/icm5bfo1?apiKey=3b83f429d264e08e515d9f0b3ce148c93f16629b' target=\"_blank\">https://wandb.ai/anandharajuds-simon-fraser-university/Fine-tune%20Llama%203%208B%20on%20Medical%20Dataset/runs/icm5bfo1?apiKey=3b83f429d264e08e515d9f0b3ce148c93f16629b</a><br> View project at: <a href='https://wandb.ai/anandharajuds-simon-fraser-university/Fine-tune%20Llama%203%208B%20on%20Medical%20Dataset?apiKey=3b83f429d264e08e515d9f0b3ce148c93f16629b' target=\"_blank\">https://wandb.ai/anandharajuds-simon-fraser-university/Fine-tune%20Llama%203%208B%20on%20Medical%20Dataset?apiKey=3b83f429d264e08e515d9f0b3ce148c93f16629b</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250324_181248-icm5bfo1/logs</code>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"messages = [\n    {\n        \"role\": \"user\",\n        \"content\": \"Hello doctor, I have bad acne. How do I get rid of it?\"\n    }\n]\n\nprompt = tokenizer.apply_chat_template(messages, tokenize=False, \n                                       add_generation_prompt=True)\n\ninputs = tokenizer(prompt, return_tensors='pt', #padding=True, \n                   truncation=True).to(\"cuda\")\n\noutputs = model.generate(**inputs, max_length=150, \n                         num_return_sequences=1)\n\ntext = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\nprint(text.split(\"assistant\")[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T18:35:42.658643Z","iopub.execute_input":"2025-03-24T18:35:42.658863Z","iopub.status.idle":"2025-03-24T18:35:56.508382Z","shell.execute_reply.started":"2025-03-24T18:35:42.658843Z","shell.execute_reply":"2025-03-24T18:35:56.507529Z"}},"outputs":[{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n\nHello. I have gone through your query and can understand your concerns. Acne is a common problem in teenagers and young adults. It is caused by the blockage of the pores of the skin by dead skin cells, oil, and bacteria. The blockage causes the pores to get\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"trainer.model.save_pretrained(new_model)\ntrainer.model.push_to_hub(new_model, use_temp_dir=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T18:35:56.509382Z","iopub.execute_input":"2025-03-24T18:35:56.509658Z","iopub.status.idle":"2025-03-24T18:36:04.321631Z","shell.execute_reply.started":"2025-03-24T18:35:56.509637Z","shell.execute_reply":"2025-03-24T18:36:04.320725Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e132fe6f7c8e4cffaf7d5cfbf17093fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/168M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"679f64cc098b4331afa6ac570685504d"}},"metadata":{}},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Anandharaju/llama-3-8b-chat-doctor/commit/8eca81c94a6e61a3f94077286235e70c016f419d', commit_message='Upload model', commit_description='', oid='8eca81c94a6e61a3f94077286235e70c016f419d', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Anandharaju/llama-3-8b-chat-doctor', endpoint='https://huggingface.co', repo_type='model', repo_id='Anandharaju/llama-3-8b-chat-doctor'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
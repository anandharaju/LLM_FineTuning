{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":120005,"sourceType":"modelInstanceVersion","modelInstanceId":100936,"modelId":121027}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%capture\n%pip install -U flash_attn\n%pip install -U exllamav2\n%pip install -U transformers \n%pip install -U datasets \n%pip install -U accelerate \n%pip install -U peft \n%pip install -U trl \n%pip install -U bitsandbytes \n%pip install -U wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T22:00:45.150671Z","iopub.execute_input":"2025-01-21T22:00:45.151081Z","iopub.status.idle":"2025-01-21T22:02:04.085721Z","shell.execute_reply.started":"2025-01-21T22:00:45.151048Z","shell.execute_reply":"2025-01-21T22:02:04.084488Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    TrainingArguments,\n    pipeline,\n    logging,\n)\nfrom peft import (\n    LoraConfig,\n    PeftModel,\n    prepare_model_for_kbit_training,\n    get_peft_model,\n)\nimport os, torch, wandb\nfrom datasets import load_dataset\nfrom trl import SFTTrainer, setup_chat_format","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T22:05:05.890562Z","iopub.execute_input":"2025-01-21T22:05:05.891093Z","iopub.status.idle":"2025-01-21T22:05:27.309185Z","shell.execute_reply.started":"2025-01-21T22:05:05.891048Z","shell.execute_reply":"2025-01-21T22:05:27.308406Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\nhf_token = user_secrets.get_secret(\"hf\")\nlogin(token = hf_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T22:05:54.267936Z","iopub.execute_input":"2025-01-21T22:05:54.268671Z","iopub.status.idle":"2025-01-21T22:05:54.468933Z","shell.execute_reply.started":"2025-01-21T22:05:54.268626Z","shell.execute_reply":"2025-01-21T22:05:54.468282Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"wb_token = user_secrets.get_secret(\"wb\")\n\nwandb.login(key=wb_token)\nrun = wandb.init(\n    project='Fine-tune Llama 3.2 on Customer Support Dataset', \n    job_type=\"training\", \n    anonymous=\"allow\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T22:05:58.134413Z","iopub.execute_input":"2025-01-21T22:05:58.134707Z","iopub.status.idle":"2025-01-21T22:06:10.540583Z","shell.execute_reply.started":"2025-01-21T22:05:58.134685Z","shell.execute_reply":"2025-01-21T22:06:10.539884Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manandharajuds\u001b[0m (\u001b[33manandharajuds-simon-fraser-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250121_220604-h3qbgjj0</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/anandharajuds-simon-fraser-university/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/h3qbgjj0?apiKey=3b83f429d264e08e515d9f0b3ce148c93f16629b' target=\"_blank\">bumbling-darkness-2</a></strong> to <a href='https://wandb.ai/anandharajuds-simon-fraser-university/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset?apiKey=3b83f429d264e08e515d9f0b3ce148c93f16629b' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/anandharajuds-simon-fraser-university/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset?apiKey=3b83f429d264e08e515d9f0b3ce148c93f16629b' target=\"_blank\">https://wandb.ai/anandharajuds-simon-fraser-university/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset?apiKey=3b83f429d264e08e515d9f0b3ce148c93f16629b</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/anandharajuds-simon-fraser-university/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/h3qbgjj0?apiKey=3b83f429d264e08e515d9f0b3ce148c93f16629b' target=\"_blank\">https://wandb.ai/anandharajuds-simon-fraser-university/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/h3qbgjj0?apiKey=3b83f429d264e08e515d9f0b3ce148c93f16629b</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Do NOT share these links with anyone. They can be used to claim your runs."},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"base_model = \"/kaggle/input/llama-3.2/transformers/3b-instruct/1\"\nnew_model = \"llama-3.2-3b-it-Ecommerce-ChatBot\"\ndataset_name = \"bitext/Bitext-customer-support-llm-chatbot-training-dataset\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T22:06:13.966057Z","iopub.execute_input":"2025-01-21T22:06:13.966371Z","iopub.status.idle":"2025-01-21T22:06:13.970672Z","shell.execute_reply.started":"2025-01-21T22:06:13.966347Z","shell.execute_reply":"2025-01-21T22:06:13.969925Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Set torch dtype and attention implementation\nif torch.cuda.get_device_capability()[0] >= 8:\n    !pip install -qqq flash-attn\n    torch_dtype = torch.bfloat16\n    attn_implementation = \"flash_attention_2\"\nelse:\n    torch_dtype = torch.float16\n    attn_implementation = \"eager\"\nattn_implementation","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T22:06:19.264948Z","iopub.execute_input":"2025-01-21T22:06:19.265247Z","iopub.status.idle":"2025-01-21T22:06:19.311728Z","shell.execute_reply.started":"2025-01-21T22:06:19.265227Z","shell.execute_reply":"2025-01-21T22:06:19.310904Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'eager'"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# QLoRA config\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch_dtype,\n    bnb_4bit_use_double_quant=True,\n)\n# Load model\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    attn_implementation=attn_implementation\n)\n\n# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T22:06:22.490958Z","iopub.execute_input":"2025-01-21T22:06:22.491286Z","iopub.status.idle":"2025-01-21T22:06:58.822347Z","shell.execute_reply.started":"2025-01-21T22:06:22.491256Z","shell.execute_reply":"2025-01-21T22:06:58.821343Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"977627c552b24cbd8dbfbda5da7a59a9"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"#Importing the dataset\ndataset = load_dataset(dataset_name, split=\"train\")\ndataset = dataset.shuffle(seed=65).select(range(1000)) # Only use 1000 samples for quick demo\ninstruction = \"\"\"You are a top-rated customer service agent named John. \n    Be polite to customers and answer all their questions.\n    \"\"\"\ndef format_chat_template(row):\n    \n    row_json = [{\"role\": \"system\", \"content\": instruction },\n               {\"role\": \"user\", \"content\": row[\"instruction\"]},\n               {\"role\": \"assistant\", \"content\": row[\"response\"]}]\n    \n    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n    return row\n\ndataset = dataset.map(\n    format_chat_template,\n    num_proc= 4,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T22:06:58.823464Z","iopub.execute_input":"2025-01-21T22:06:58.823709Z","iopub.status.idle":"2025-01-21T22:07:01.193847Z","shell.execute_reply.started":"2025-01-21T22:06:58.823687Z","shell.execute_reply":"2025-01-21T22:07:01.192673Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/11.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db11dd70deff4b29bdfecaffaf3f75a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)t_Training_Dataset_27K_responses-v11.csv:   0%|          | 0.00/19.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13349e8594d24ad69e99e402645aabed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/26872 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59b328b2ecf5497fb3cc23238e50d813"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce5f902b35464b618c28c77b34340ee8"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"dataset['text'][3]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T22:07:05.990154Z","iopub.execute_input":"2025-01-21T22:07:05.990497Z","iopub.status.idle":"2025-01-21T22:07:06.000779Z","shell.execute_reply.started":"2025-01-21T22:07:05.990457Z","shell.execute_reply":"2025-01-21T22:07:06.000111Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a top-rated customer service agent named John. \\n    Be polite to customers and answer all their questions.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\ncould you tell me about the options for shipping?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nOf course, I'd be delighted to provide you with information about our shipping options! Here are the various choices we offer:\\n\\n1. Standard Shipping: This option typically arrives within {{Date Range}} business days, catering to non-urgent items and ensuring a cost-effective delivery.\\n\\n2. Expedited Shipping: If you're looking for a faster option, choose expedited shipping. Your items will reach you within {{Date Range}} business days, offering a balance between speed and affordability.\\n\\n3. Overnight Shipping: For urgent needs, we have overnight shipping. This ensures your items are delivered on the next business day, offering the highest level of speed and convenience.\\n\\n4. In-Store Pickup: If you prefer a more hands-on approach, you can opt for in-store pickup. This option allows you to collect your items personally from one of our {{Store Location}}, offering added flexibility and convenience.\\n\\nRemember that specific delivery times may vary based on your location and other factors. If you have any further questions or need assistance with any aspect of our shipping options, please feel free to ask. We're here to ensure your satisfaction!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\""},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"import bitsandbytes as bnb\n\ndef find_all_linear_names(model):\n    cls = bnb.nn.Linear4bit\n    lora_module_names = set()\n    for name, module in model.named_modules():\n        if isinstance(module, cls):\n            names = name.split('.')\n            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n    if 'lm_head' in lora_module_names:  # needed for 16 bit\n        lora_module_names.remove('lm_head')\n    return list(lora_module_names)\n\nmodules = find_all_linear_names(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T22:07:09.659525Z","iopub.execute_input":"2025-01-21T22:07:09.659940Z","iopub.status.idle":"2025-01-21T22:07:09.668270Z","shell.execute_reply.started":"2025-01-21T22:07:09.659904Z","shell.execute_reply":"2025-01-21T22:07:09.667404Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# LoRA config\npeft_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=modules\n)\ntokenizer.chat_template = None\nmodel, tokenizer = setup_chat_format(model, tokenizer)\nmodel = get_peft_model(model, peft_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T22:07:34.416402Z","iopub.execute_input":"2025-01-21T22:07:34.416705Z","iopub.status.idle":"2025-01-21T22:07:42.175421Z","shell.execute_reply.started":"2025-01-21T22:07:34.416682Z","shell.execute_reply":"2025-01-21T22:07:42.174681Z"}},"outputs":[{"name":"stderr","text":"The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"#Hyperparamter\ntraining_arguments = TrainingArguments(\n    output_dir=new_model,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    gradient_accumulation_steps=2,\n    optim=\"paged_adamw_32bit\",\n    num_train_epochs=1,\n    eval_strategy=\"steps\",\n    eval_steps=0.2,\n    logging_steps=1,\n    warmup_steps=10,\n    logging_strategy=\"steps\",\n    learning_rate=2e-4,\n    fp16=False,\n    bf16=False,\n    group_by_length=True,\n    report_to=\"wandb\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T22:07:50.723015Z","iopub.execute_input":"2025-01-21T22:07:50.723322Z","iopub.status.idle":"2025-01-21T22:07:50.757882Z","shell.execute_reply.started":"2025-01-21T22:07:50.723297Z","shell.execute_reply":"2025-01-21T22:07:50.757195Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Setting sft parameters\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset,\n    eval_dataset=dataset,\n    peft_config=peft_config,\n    #max_seq_length= 512,\n    #dataset_text_field=\"text\",\n    tokenizer=tokenizer,\n    args=training_arguments,\n    #packing= False,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T22:08:27.903429Z","iopub.execute_input":"2025-01-21T22:08:27.903791Z","iopub.status.idle":"2025-01-21T22:08:29.262693Z","shell.execute_reply.started":"2025-01-21T22:08:27.903760Z","shell.execute_reply":"2025-01-21T22:08:29.262066Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-13-b7e9403c71f8>:2: FutureWarning: `tokenizer` is deprecated and removed starting from version 0.16.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n  trainer = SFTTrainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f19d3bf272a1496c94352bdc9dcb6eec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43876a4fce364edf9b9f22ae5385d60a"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T22:11:09.671975Z","iopub.execute_input":"2025-01-21T22:11:09.672450Z","iopub.status.idle":"2025-01-21T22:32:27.504601Z","shell.execute_reply.started":"2025-01-21T22:11:09.672407Z","shell.execute_reply":"2025-01-21T22:32:27.503714Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [500/500 21:15, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.840100</td>\n      <td>0.797782</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.596500</td>\n      <td>0.684234</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.701500</td>\n      <td>0.604993</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.489300</td>\n      <td>0.555960</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.466900</td>\n      <td>0.535601</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=500, training_loss=0.7579015807509423, metrics={'train_runtime': 1277.1724, 'train_samples_per_second': 0.783, 'train_steps_per_second': 0.391, 'total_flos': 3072774910715904.0, 'train_loss': 0.7579015807509423, 'epoch': 1.0})"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"wandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T22:32:42.339981Z","iopub.execute_input":"2025-01-21T22:32:42.340358Z","iopub.status.idle":"2025-01-21T22:32:43.944212Z","shell.execute_reply.started":"2025-01-21T22:32:42.340326Z","shell.execute_reply":"2025-01-21T22:32:43.943425Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▅▃▂▁</td></tr><tr><td>eval/runtime</td><td>█▃▆▃▁</td></tr><tr><td>eval/samples_per_second</td><td>▁▆▃▆█</td></tr><tr><td>eval/steps_per_second</td><td>▁▆▃▆█</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▄█▅▅▄▃▃▄▁▂▅▄▅▁▃▂▄▁▁▃▃▃▃▃▂▂▄▅▂▂▂▂▂▅▂▄▃▂▃▅</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▇▇█▇▆▇▆▅▃▄▄▄▄▆▅▅▃▃▃▂▆▄▂▂▂▂▅▂▄▆▁▂▅▃▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.5356</td></tr><tr><td>eval/runtime</td><td>173.1565</td></tr><tr><td>eval/samples_per_second</td><td>5.775</td></tr><tr><td>eval/steps_per_second</td><td>5.775</td></tr><tr><td>total_flos</td><td>3072774910715904.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>500</td></tr><tr><td>train/grad_norm</td><td>1.10789</td></tr><tr><td>train/learning_rate</td><td>0</td></tr><tr><td>train/loss</td><td>0.4669</td></tr><tr><td>train_loss</td><td>0.7579</td></tr><tr><td>train_runtime</td><td>1277.1724</td></tr><tr><td>train_samples_per_second</td><td>0.783</td></tr><tr><td>train_steps_per_second</td><td>0.391</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">bumbling-darkness-2</strong> at: <a href='https://wandb.ai/anandharajuds-simon-fraser-university/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/h3qbgjj0?apiKey=3b83f429d264e08e515d9f0b3ce148c93f16629b' target=\"_blank\">https://wandb.ai/anandharajuds-simon-fraser-university/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/h3qbgjj0?apiKey=3b83f429d264e08e515d9f0b3ce148c93f16629b</a><br> View project at: <a href='https://wandb.ai/anandharajuds-simon-fraser-university/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset?apiKey=3b83f429d264e08e515d9f0b3ce148c93f16629b' target=\"_blank\">https://wandb.ai/anandharajuds-simon-fraser-university/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset?apiKey=3b83f429d264e08e515d9f0b3ce148c93f16629b</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250121_220604-h3qbgjj0/logs</code>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"messages = [{\"role\": \"system\", \"content\": instruction},\n    {\"role\": \"user\", \"content\": \"I bought the same item twice, cancel order {{Order Number}}\"}]\n\nprompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    \ninputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n\noutputs = model.generate(**inputs, max_new_tokens=150, num_return_sequences=1)\n\ntext = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\nprint(text.split(\"assistant\")[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T22:32:45.934364Z","iopub.execute_input":"2025-01-21T22:32:45.934685Z","iopub.status.idle":"2025-01-21T22:33:03.696687Z","shell.execute_reply.started":"2025-01-21T22:32:45.934657Z","shell.execute_reply":"2025-01-21T22:33:03.695818Z"}},"outputs":[{"name":"stdout","text":"\nI'm sorry to hear that you've purchased the same item twice and would like to cancel order number {{Order Number}}. I understand that this might be a mistake or an error, and I'm here to assist you in resolving this issue. To proceed with the cancellation, I'll need some additional information from you. Could you please provide me with your full name, email address, and the order number again? With these details, I'll be able to locate the relevant information and assist you further. Thank you for bringing this to my attention, and I apologize for any inconvenience caused.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# Save the fine-tuned model\ntrainer.model.save_pretrained(new_model)\ntrainer.model.push_to_hub(new_model, use_temp_dir=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T22:33:03.697688Z","iopub.execute_input":"2025-01-21T22:33:03.697965Z","iopub.status.idle":"2025-01-21T22:33:58.036685Z","shell.execute_reply.started":"2025-01-21T22:33:03.697937Z","shell.execute_reply":"2025-01-21T22:33:58.035814Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b5831cd0a3d4bc0bb2b5afab937e135"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/1.67G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11193149ffca4a0c84d94019d197c21f"}},"metadata":{}},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Anandharaju/llama-3.2-3b-it-Ecommerce-ChatBot/commit/fafb28c57f71324e640e84a8eb65d1574ab99943', commit_message='Upload model', commit_description='', oid='fafb28c57f71324e640e84a8eb65d1574ab99943', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Anandharaju/llama-3.2-3b-it-Ecommerce-ChatBot', endpoint='https://huggingface.co', repo_type='model', repo_id='Anandharaju/llama-3.2-3b-it-Ecommerce-ChatBot'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":19}]}